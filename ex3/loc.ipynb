{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecion object localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You should run \"import libraris\", \"initialization\" and \"test\" to test model\n",
    "#### You should run \"data file generation\" to make a new csv file. Don't forget to check and change the filenames!\n",
    "#### You should run \"import libraris\", \"initialization\" and \"train\" to train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* data file generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e480bebec202>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-e480bebec202>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mxml_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/*xml\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATASET_FOLDER\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxml_file\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxml_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mET\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxml_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATASET_FOLDER\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./filename\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\envs\\env\\lib\\xml\\etree\\ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(source, parser)\u001b[0m\n\u001b[0;32m   1195\u001b[0m     \"\"\"\n\u001b[0;32m   1196\u001b[0m     \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mElementTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1197\u001b[1;33m     \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1198\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\envs\\env\\lib\\xml\\etree\\ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, source, parser)\u001b[0m\n\u001b[0;32m    585\u001b[0m         \u001b[0mclose_source\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m             \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m             \u001b[0mclose_source\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "DATASET_FOLDER = \"mixed_images/\"\n",
    "TRAIN_OUTPUT_FILE = \"mixed_train.csv\"\n",
    "VALIDATION_OUTPUT_FILE = \"mixed_validation.csv\"\n",
    "\n",
    "SPLIT_RATIO = 0.8\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(DATASET_FOLDER):\n",
    "        print(\"Dataset not found\")\n",
    "        return\n",
    "\n",
    "    class_names = {}\n",
    "    k = 0\n",
    "    output = []\n",
    "    xml_files = glob.glob(\"{}/*xml\".format(DATASET_FOLDER))\n",
    "    for i, xml_file in enumerate(xml_files):\n",
    "        tree = ET.parse(xml_file)\n",
    "\n",
    "        path = os.path.join(DATASET_FOLDER, tree.findtext(\"./filename\"))\n",
    "\n",
    "        height = int(tree.findtext(\"./size/height\"))\n",
    "        width = int(tree.findtext(\"./size/width\"))\n",
    "        xmin = int(tree.findtext(\"./object/bndbox/xmin\"))\n",
    "        ymin = int(tree.findtext(\"./object/bndbox/ymin\"))\n",
    "        xmax = int(tree.findtext(\"./object/bndbox/xmax\"))\n",
    "        ymax = int(tree.findtext(\"./object/bndbox/ymax\"))\n",
    "\n",
    "        basename = os.path.basename(path)\n",
    "        basename = os.path.splitext(basename)[0]\n",
    "        class_name = basename[:basename.rfind(\"_\")].lower()\n",
    "        if class_name not in class_names:\n",
    "            class_names[class_name] = k\n",
    "            k += 1\n",
    "\n",
    "        output.append((path, height, width, xmin, ymin, xmax, ymax, class_name, class_names[class_name]))\n",
    "\n",
    "    # preserve percentage of samples for each class (\"stratified\")\n",
    "    output.sort(key=lambda tup : tup[-1])\n",
    "\n",
    "    lengths = []\n",
    "    i = 0\n",
    "    last = 0\n",
    "    for j, row in enumerate(output):\n",
    "        if last == row[-1]:\n",
    "            i += 1\n",
    "        else:\n",
    "            print(\"class {}: {} images\".format(output[j-1][-2], i))\n",
    "            lengths.append(i)\n",
    "            i = 1\n",
    "            last += 1\n",
    "\n",
    "    print(\"class {}: {} images\".format(output[j-1][-2], i))\n",
    "    lengths.append(i)\n",
    "\n",
    "    with open(TRAIN_OUTPUT_FILE, \"w\", newline='') as train, open(VALIDATION_OUTPUT_FILE, \"w\", newline='') as validate:\n",
    "        writer = csv.writer(train, delimiter=\",\")\n",
    "        writer2 = csv.writer(validate, delimiter=\",\")\n",
    "\n",
    "        s = 0\n",
    "        for c in lengths:\n",
    "            for i in range(c):\n",
    "                print(\"{}/{}\".format(s + 1, sum(lengths)), end=\"\\r\")\n",
    "\n",
    "                path, height, width, xmin, ymin, xmax, ymax, class_name, class_id = output[s]\n",
    "\n",
    "                if xmin >= xmax or ymin >= ymax or xmax > width or ymax > height or xmin < 0 or ymin < 0:\n",
    "                    print(\"Warning: {} contains invalid box. Skipped...\".format(path))\n",
    "                    continue\n",
    "\n",
    "                row = [path, height, width, xmin, ymin, xmax, ymax, class_name, class_names[class_name]]\n",
    "                if i <= c * SPLIT_RATIO:\n",
    "                    writer.writerow(row)\n",
    "                else:\n",
    "                    writer2.writerow(row)\n",
    "\n",
    "                s += 1\n",
    "\n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.layers import Concatenate, Conv2D, UpSampling2D, Reshape, BatchNormalization, Activation\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.backend import epsilon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.35, 0.5, 0.75, 1.0\n",
    "ALPHA = 1.0\n",
    "\n",
    "GRID_SIZE = 28\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "# first train with frozen weights, then fine tune\n",
    "TRAINABLE = False\n",
    "WEIGHTS = \"model-0.89.h5\"\n",
    "\n",
    "EPOCHS = 100 # 200\n",
    "BATCH_SIZE = 70 # 8\n",
    "PATIENCE = 6\n",
    "\n",
    "MULTI_PROCESSING = False\n",
    "THREADS = 1\n",
    "\n",
    "TRAIN_CSV = \"mixed_train.csv\"\n",
    "VALIDATION_CSV = \"mixed_validation.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, csv_file):\n",
    "        self.paths = []\n",
    "\n",
    "        with open(csv_file, \"r\") as file:\n",
    "            self.mask = np.zeros((sum(1 for line in file), GRID_SIZE, GRID_SIZE))\n",
    "            file.seek(0)\n",
    "\n",
    "            reader = csv.reader(file, delimiter=\",\")\n",
    "\n",
    "            for index, row in enumerate(reader):\n",
    "                for i, r in enumerate(row[1:7]):\n",
    "                    row[i+1] = int(r)\n",
    "\n",
    "                path, image_height, image_width, x0, y0, x1, y1, _, _ = row\n",
    "\n",
    "                cell_start_x = np.rint(((GRID_SIZE - 1) / image_width) * x0).astype(int)\n",
    "                cell_stop_x = np.rint(((GRID_SIZE - 1) / image_width) * x1).astype(int)\n",
    "\n",
    "                cell_start_y = np.rint(((GRID_SIZE - 1) / image_height) * y0).astype(int)\n",
    "                cell_stop_y = np.rint(((GRID_SIZE - 1) / image_height) * y1).astype(int)\n",
    "\n",
    "                self.mask[index, cell_start_y : cell_stop_y, cell_start_x : cell_stop_x] = 1\n",
    "\n",
    "                self.paths.append(path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.mask) / BATCH_SIZE)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_paths = self.paths[idx * BATCH_SIZE:(idx + 1) * BATCH_SIZE]\n",
    "        batch_masks = self.mask[idx * BATCH_SIZE:(idx + 1) * BATCH_SIZE]\n",
    "\n",
    "        batch_images = np.zeros((len(batch_paths), IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.float32)\n",
    "        for i, f in enumerate(batch_paths):\n",
    "            img = Image.open(f)\n",
    "            img = img.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "            batch_images[i] = preprocess_input(np.array(img, dtype=np.float32))\n",
    "            img.close()\n",
    "\n",
    "        return batch_images, batch_masks[:,:,:,np.newaxis]\n",
    "\n",
    "class Validation(Callback):\n",
    "    def __init__(self, generator):\n",
    "        self.generator = generator\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        numerator = 0\n",
    "        denominator = 0\n",
    "\n",
    "        for i in range(len(self.generator)):\n",
    "            batch_images, gt = self.generator[i]\n",
    "            pred = self.model.predict_on_batch(batch_images)\n",
    "\n",
    "            pred[pred >= 0.6] = 1\n",
    "            pred[pred < 0.6] = 0\n",
    "\n",
    "            numerator += 2 * np.sum(gt * pred)\n",
    "            denominator += np.sum(gt + pred)\n",
    "\n",
    "        dice = np.round(numerator / denominator, 4)\n",
    "        logs[\"val_dice\"] = dice\n",
    "\n",
    "        print(\" - val_dice: {}\".format(dice))\n",
    "\n",
    "def create_model(trainable=True):\n",
    "    model = MobileNetV2(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, alpha=ALPHA, weights=\"imagenet\")\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    block1 = model.get_layer(\"block_5_add\").output\n",
    "    block2 = model.get_layer(\"block_12_add\").output\n",
    "    block3 = model.get_layer(\"block_15_add\").output\n",
    "\n",
    "    blocks = [block2, block1]\n",
    "\n",
    "    x = block3\n",
    "    for block in blocks:\n",
    "        x = UpSampling2D()(x)\n",
    "\n",
    "        x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        x = Concatenate()([x, block])\n",
    "\n",
    "        x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        \n",
    "        x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        \n",
    "        x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(1, kernel_size=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    return Model(inputs=model.input, outputs=x)\n",
    "\n",
    "def loss(y_true, y_pred):\n",
    "    def dice_coefficient(y_true, y_pred):\n",
    "        numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=-1)\n",
    "        denominator = tf.reduce_sum(y_true + y_pred, axis=-1)\n",
    "\n",
    "        return numerator / (denominator + epsilon())\n",
    "\n",
    "    return binary_crossentropy(y_true, y_pred) - tf.math.log(dice_coefficient(y_true, y_pred) + epsilon())\n",
    "\n",
    "def main():\n",
    "    model = create_model(trainable=TRAINABLE)\n",
    "#     model.summary()\n",
    "    with open('cnn.json', 'w') as model_file:\n",
    "            model_file.write(model.to_json())\n",
    "\n",
    "    if TRAINABLE:\n",
    "        model.load_weights(WEIGHTS)\n",
    "\n",
    "    train_datagen = DataGenerator(TRAIN_CSV)\n",
    "    validation_datagen = Validation(generator=DataGenerator(VALIDATION_CSV))\n",
    "\n",
    "    optimizer = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=[])\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(\"model-{val_dice:.2f}.h5\", monitor=\"val_dice\", verbose=1, save_best_only=True,\n",
    "                                 save_weights_only=True, mode=\"max\")\n",
    "    stop = EarlyStopping(monitor=\"val_dice\", patience=PATIENCE, mode=\"max\")\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=\"val_dice\", factor=0.2, patience=5, min_lr=1e-6, verbose=1, mode=\"max\")\n",
    "\n",
    "    model.fit_generator(generator=train_datagen,\n",
    "                        epochs=EPOCHS,\n",
    "                        callbacks=[validation_datagen, checkpoint, reduce_lr, stop],\n",
    "                        workers=THREADS,\n",
    "                        use_multiprocessing=MULTI_PROCESSING,\n",
    "                        shuffle=True,\n",
    "                        verbose=1)\n",
    "    # print(train_datagen[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0819 10:54:40.423204  6616 deprecation.py:506] From F:\\ProgramData\\envs\\env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0819 10:54:55.912587  6616 deprecation.py:323] From F:\\ProgramData\\envs\\env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/9 [==>...........................] - ETA: 6:11 - loss: 14.0003"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-972361fa1b80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-61bbc206392a>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    140\u001b[0m                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMULTI_PROCESSING\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m                         verbose=1)\n\u001b[0m\u001b[0;32m    143\u001b[0m     \u001b[1;31m# print(train_datagen[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\envs\\env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1433\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32mF:\\ProgramData\\envs\\env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\envs\\env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1173\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\envs\\env\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mF:\\ProgramData\\envs\\env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 12:44:15.117858  7432 deprecation.py:506] From F:\\ProgramData\\envs\\olymp_school\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0816 12:44:15.121859  7432 deprecation.py:506] From F:\\ProgramData\\envs\\olymp_school\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0816 12:44:15.125855  7432 deprecation.py:506] From F:\\ProgramData\\envs\\olymp_school\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#from train import *\n",
    "import cv2\n",
    "import glob\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "WEIGHTS_FILE = \"model-0.84.h5\" # Loading weights\n",
    "IMAGES = \"iccet.photos.bratva.new/*jpg\" # Validation images /old_val, val, iccet.photos.bratva/\n",
    "EPSILON = 0.02\n",
    "\n",
    "def main():\n",
    "    # Loading model from json\n",
    "    json_file = open(\"cnn.json\", \"r\")\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    # Создаем модель на основе загруженных данных\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    # model = create_model()\n",
    "    model.load_weights(WEIGHTS_FILE)\n",
    "\n",
    "    for filename in glob.glob(IMAGES):\n",
    "        unscaled = cv2.imread(filename)\n",
    "        copy_unscaled = np.copy(unscaled)\n",
    "        image = cv2.resize(unscaled, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        feat_scaled = preprocess_input(np.array(image, dtype=np.float32))\n",
    "\n",
    "        region = np.squeeze(model.predict(feat_scaled[np.newaxis,:]))\n",
    "\n",
    "        output = np.zeros(region.shape, dtype=np.uint8)\n",
    "        output[region > 0.5] = 1\n",
    "        \n",
    "        __, contours, _ = cv2.findContours(output, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for cnt in contours:\n",
    "            approx = cv2.approxPolyDP(cnt, EPSILON * cv2.arcLength(cnt, True), True)\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "            \n",
    "            # Coordinates of objects\n",
    "            x0 = np.rint(x * unscaled.shape[1] / output.shape[1]).astype(int)\n",
    "            x1 = np.rint((x + w) * unscaled.shape[1] / output.shape[1]).astype(int)\n",
    "            y0 = np.rint(y * unscaled.shape[0] / output.shape[0]).astype(int)\n",
    "            y1 = np.rint((y + h) * unscaled.shape[0] / output.shape[0]).astype(int)\n",
    "            # Selection by area\n",
    "            if (x1-x0)*(y1-y0) > 20000:\n",
    "                cv2.rectangle(unscaled, (x0, y0), (x1, y1), (0, 128, 0), 2)\n",
    "                cv2.line(unscaled, (x0+(x1-x0)//2, y0), (x0+(x1-x0)//2, y1), (255, 0, 0))\n",
    "                cv2.line(unscaled, (x0, y0+(y1-y0)//2), (x1, y0+(y1-y0)//2), (255, 0, 0))\n",
    "                \n",
    "                cx, cy = x0+(x1-x0)//2, y0+(y1-y0)//2 # Coordinates of center\n",
    "                cv2.putText(unscaled, \n",
    "                            f\"x: {cx}, y: {cy}\", \n",
    "                            (cx + 10, cy - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                            0.5, (128, 0, 255), \n",
    "                            lineType=cv2.LINE_AA)\n",
    "                \n",
    "                # Calculating center shift\n",
    "                h, w = unscaled.shape[:2]\n",
    "                shift = w//2 - cx\n",
    "                cv2.putText(unscaled, \n",
    "                            f\"Move on: {shift}\", \n",
    "                            (4, 20), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                            0.8, (100, 0, 255), \n",
    "                            lineType=cv2.LINE_AA)\n",
    "                \n",
    "                # Crop image for classification\n",
    "                crop = copy_unscaled[y0:y1, x0:x1]\n",
    "                cv2.imshow(\"crop\", crop)\n",
    "                cv2.waitKey(0)\n",
    "                \n",
    "                '''classification'''\n",
    "\n",
    "        cv2.imshow(\"image\", unscaled)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "F = \"old_val\"\n",
    "\n",
    "for file in glob.glob(\"F/*.jpg\"):\n",
    "    #     new = file[:file.rfind(\".\")] + '000' + file[file.rfind(\".\"):]\n",
    "    #     os.rename(file, new)\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
